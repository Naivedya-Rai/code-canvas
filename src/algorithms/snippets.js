const snippets = [
  {
    algo: "A*-Algorithm-Manhattan-Distance",
    code: "/*==========A* Algorithm: Finding the Shortest Path in a Graph==============\r\n\r\nA* (pronounced as 'A star') is a widely used pathfinding algorithm known for its efficiency in\r\n finding the shortest path between two nodes in a graph or grid.\r\n In this tutorial, we'll explore how A* works, its pros and cons, time complexity, and common applications.\r\n\r\nAlgorithm Overview:\r\n-------------------\r\n\r\n1. Initialize the starting node's distance from the start and the\r\n estimated distance to the end (heuristic).\r\n\r\n2. Create a priority queue to track nodes to visit,\r\n starting with the initial node.\r\n\r\n3. While there are nodes to visit:\r\n  - Remove the node with the minimum estimated total distance from the queue.\r\n  - If the removed node is the end node, stop the search.\r\n\r\n4. Get neighboring nodes of the current node and process each neighbor:\r\n  - Skip walls (obstacles).\r\n  - Calculate the tentative distance from the start to the neighbor.\r\n  - If the tentative distance is greater than or equal to the neighbor's current distance, skip it.\r\n  - Update the neighbor's data (distance and the heuristic).\r\n  - Add the neighbor to the priority queue if it's not there,\r\n or update it if it is.\r\n\r\n5. Return the path from the end node to the start node, if found.\r\n\r\nPros:\r\n-----\r\n  - A* guarantees finding the shortest path in weighted graphs\r\n with non-negative edge weights.\r\n  - It's efficient and widely used in route planning, navigation,\r\n and game development.\r\n  - It's versatile and can handle various types of grids or graphs.\r\n\r\nCons:\r\n-----\r\n  - Inefficient for graphs with negative edge weights or cycles.\r\n\r\nTime Complexity:\r\n----------------\r\n  - A* has a time complexity of O((V + E) * log(V)), where V is the number of nodes (vertices)\r\n and E is the number of edges in the graph.\r\n It's efficient for many applications.\r\n\r\nUsage:\r\n------\r\n  - A* is used in route planning for navigation systems,\r\n video games, robotics, and various optimization problems.*/\r\n\r\nfunction aStarAlgorithm(startNode, endNode, nodesGraph) {\r\n  startNode.distanceFromStart = 0;\r\n  startNode.estimatedDistanceToEnd = calculateManhattanDistance(\r\n    startNode,\r\n    endNode\r\n  );\r\n  const nodesToVisit = new MinHeap([startNode]);\r\n\r\n  while (!nodesToVisit.isEmpty()) {\r\n    const currentMinDistanceNode = nodesToVisit.remove();\r\n    if (currentMinDistanceNode === endNode) break;\r\n    const neighbors = getNeighbors(currentMinDistanceNode, nodesGraph);\r\n    for (const neighbor of neighbors) {\r\n      if (neighbor.isWall) continue;\r\n      const tentativeDistanceToNeighbor =\r\n        currentMinDistanceNode.distanceFromStart + neighbor.weight;\r\n      if (tentativeDistanceToNeighbor >= neighbor.distanceFromStart) continue;\r\n      neighbor.cameFrom = currentMinDistanceNode;\r\n      neighbor.distanceFromStart = tentativeDistanceToNeighbor;\r\n      neighbor.estimatedDistanceToEnd =\r\n        tentativeDistanceToNeighbor +\r\n        calculateManhattanDistance(neighbor, endNode);\r\n      if (!nodesToVisit.containsNode(neighbor)) nodesToVisit.insert(neighbor);\r\n      else nodesToVisit.update(neighbor);\r\n    }\r\n  }\r\n  return reconstructPath(endNode);\r\n}\r\n\r\nfunction calculateManhattanDistance(currentNode, endNode) {\r\n  return (\r\n    Math.abs(currentNode.row - endNode.row) +\r\n    Math.abs(currentNode.col - endNode.col)\r\n  );\r\n}\r\n\r\nfunction getNeighbors(node, nodesGraph) {\r\n  const neighbors = [];\r\n  const nodesGraphHeight = nodesGraph.length - 1;\r\n  const nodesGraphWidth = nodesGraph[0].length - 1;\r\n  const { row, col } = node;\r\n  if (row + 1 <= nodesGraphHeight) neighbors.push(nodesGraph[row + 1][col]);\r\n  if (row - 1 >= 0) neighbors.push(nodesGraph[row - 1][col]);\r\n  if (col + 1 <= nodesGraphWidth) neighbors push(nodesGraph[row][col + 1]);\r\n  if (col - 1 >= 0) neighbors.push(nodesGraph[row][col - 1]);\r\n  return neighbors;\r\n}\r\n\r\nfunction reconstructPath(endNode) {\r\n  if (!endNode.cameFrom) return [];\r\n  const path = [];\r\n  let currentNode = endNode;\r\n  while (currentNode) {\r\n    path.push([currentNode.row, currentNode.col]);\r\n    currentNode = currentNode.cameFrom;\r\n  }\r\n  return path.reverse();\r\n}",
  },
  {
    algo: "A*-Algorithm-Diagonal-Distance",
    code: "/*A* Algorithm: Finding the Shortest Path in a Weighted Graph using diagonal distance\r\n\r\nA* algorithm is a versatile and efficient graph traversal algorithm\r\n used to find the shortest path in weighted graphs.\r\n It's widely applied in pathfinding, robotics, and gaming.\r\n In this tutorial, we'll provide an in-depth explanation of A* algorithm's operation,\r\n its advantages and drawbacks, time complexity, and common use cases.\r\n\r\nAlgorithm Overview: \r\n-------------------\r\n\r\n1. Initialize the start node's distance from the start as 0 and estimated distance to the end.\r\n\r\n2. Create a priority queue and add the start node.\r\n\r\n3. While the priority queue is not empty: \r\n  - Get the node with the minimum total estimated distance from the queue.\r\n    - If it's the end node, the path is found; exit the loop.\r\n\r\n4. Retrieve neighbors of the current node.\r\n\r\n5. For each neighbor: \r\n  - Skip walls.\r\n    - Calculate the tentative distance to the neighbor.\r\n      - If it's greater than or equal to the neighbor's current distance, skip it.\r\n        - Update the neighbor's details and insert or update it in the priority queue.\r\n\r\n6. Return the reconstructed path from the end node to the start node.\r\n\r\nPros: \r\n-----\r\n  - A* algorithm guarantees the shortest path in weighted graphs.\r\n  - It's highly efficient, considering both the distance traveled and estimated distance to the goal.\r\n\r\nCons: \r\n-----\r\n  - It may perform poorly in graphs with high branching factors, consuming more memory and time.\r\n  - Heuristic choices and graph characteristics can impact its efficiency.\r\n\r\nTime Complexity: \r\n----------------\r\n  - With an efficient priority queue,\r\n A* algorithm has a time complexity of O((V + E) * log(V)),\r\n where V is the number of nodes(vertices) and E is the number of edges in the graph.\r\n  - It's suitable for practical purposes, even in large graphs.\r\n\r\nUsage: \r\n------\r\n  - A* algorithm is applied in navigation, robotics, and games for pathfinding \r\n and optimizing routes.\r\n\r\n*/\r\n function aStarAlgorithm(startNode, endNode, nodesGraph) {\r\n  startNode.distanceFromStart = 0;\r\n  startNode.estimatedDistanceToEnd = calculateDiagonalDistance(startNode, endNode);\r\n  const nodesToVisit = new MinHeap([startNode]);\r\n  while (!nodesToVisit.isEmpty()) {\r\n    const currentMinDistanceNode = nodesToVisit.remove();\r\n    if (currentMinDistanceNode === endNode) break;\r\n    const neighbors = getNeighbors(currentMinDistanceNode, nodesGraph);\r\n    for (const neighbor of neighbors) {\r\n      if (neighbor.isWall) continue;\r\n      const tentativeDistanceToNeighbor =\r\n        currentMinDistanceNode.distanceFromStart + neighbor.weight;\r\n      if (tentativeDistanceToNeighbor >= neighbor.distanceFromStart) continue;\r\n      neighbor.cameFrom = currentMinDistanceNode;\r\n      neighbor.distanceFromStart = tentativeDistanceToNeighbor;\r\n      neighbor.estimatedDistanceToEnd =\r\n        tentativeDistanceToNeighbor + calculateDiagonalDistance(neighbor, endNode);\r\n      if (!nodesToVisit.containsNode(neighbor)) nodesToVisit.insert(neighbor);\r\n      else nodesToVisit.update(neighbor);\r\n    }\r\n  }\r\n  return reconstructPath(endNode);\r\n}\r\n\r\nfunction calculateDiagonalDistance(currentNode, finishNode) {\r\n  const { row, col } = currentNode;\r\n  const { row: fRow, col: fCol } = finishNode;\r\n  const NORMAL_COST = 1;\r\n  const DIAGONAL_COST = NORMAL_COST * 1.414;\r\n  const dMax = Math.max(Math.abs(row - fRow), Math.abs(col - fCol);\r\n  const dMin = Math.min(Math.abs(row - fRow), Math.abs(col - fCol);\r\n  return DIAGONAL_COST * dMin + NORMAL_COST * (dMax - dMin);\r\n}\r\n\r\nfunction getNeighbors(node, nodesGraph) {\r\n  const neighbors = [];\r\n  const nodesGraphHeight = nodesGraph.length - 1;\r\n  const nodesGraphWidth = nodesGraph[0].length - 1;\r\n  const { row, col } = node;\r\n  if (row + 1 <= nodesGraphHeight) neighbors.push(nodesGraph[row + 1][col]);\r\n  if (row - 1 >= 0) neighbors.push(nodesGraph[row - 1][col]);\r\n  if (col + 1 <= nodesGraphWidth) neighbors push(nodesGraph[row][col + 1]);\r\n  if (col - 1 >= 0) neighbors.push(nodesGraph[row][col - 1]);\r\n  if (row > 0 && col > 0) neighbors.push(nodesGraph[row - 1][col - 1]);\r\n  if (row > 0 && col < nodesGraphWidth) neighbors.push(nodesGraph[row - 1][col + 1]);\r\n  if (row < nodesGraphWidth && col < nodesGraphWidth)\r\n    neighbors.push(nodesGraph[row + 1][col + 1]);\r\n  if (row < nodesGraphWidth && col > 0) neighbors.push(nodesGraph[row + 1][col - 1]);\r\n  return neighbors;\r\n}\r\n\r\nfunction reconstructPath(endNode) {\r\n  if (!endNode.cameFrom) return [];\r\n  const path = [];\r\n  let currentNode = endNode;\r\n  while (currentNode) {\r\n    path.push([currentNode.row, currentNode.col]);\r\n    currentNode = currentNode.cameFrom;\r\n  }\r\n  return path.reverse();\r\n}",
  },
  {
    algo: "Dynamic-Path-finding",
    code: "function aStarAlgorithm(startNode, endNode, nodesGraph) {\r\n  startNode.distanceFromStart = 0;\r\n  startNode.estimatedDistanceToEnd = calculateManhattanDistance(\r\n    startNode,\r\n    endNode\r\n  );\r\n  const nodesToVisit = new MinHeap([startNode]);\r\n\r\n  while (!nodesToVisit.isEmpty()) {\r\n    const currentMinDistanceNode = nodesToVisit.remove();\r\n\r\n    if (currentMinDistanceNode === endNode) break;\r\n\r\n    const neighbors = getNeighbors(currentMinDistanceNode, nodesGraph);\r\n    for (const neighbor of neighbors) {\r\n      if (neighbor.isWall) continue;\r\n\r\n      const tentativeDistanceToNeighbor =\r\n        currentMinDistanceNode.distanceFromStart + neighbor.weight;\r\n\r\n      if (tentativeDistanceToNeighbor >= neighbor.distanceFromStart) continue;\r\n\r\n      neighbor.cameFrom = currentMinDistanceNode;\r\n      neighbor.distanceFromStart = tentativeDistanceToNeighbor;\r\n      neighbor.estimatedDistanceToEnd =\r\n        tentativeDistanceToNeighbor +\r\n        calculateManhattanDistance(neighbor, endNode);\r\n\r\n      if (!nodesToVisit.containsNode(neighbor)) nodesToVisit.insert(neighbor);\r\n      else nodesToVisit.update(neighbor);\r\n    }\r\n  }\r\n  return reconstructPath(endNode);\r\n}\r\n\r\nfunction calculateManhattanDistance(currentNode, endNode) {\r\n  return (\r\n    Math.abs(currentNode.row - endNode.row) +\r\n    Math.abs(currentNode.col - endNode.col)\r\n  );\r\n}\r\n\r\nfunction getNeighbors(node, nodesGraph) {\r\n  const neighbors = [];\r\n  const nodesGraphHeight = nodesGraph.length - 1;\r\n  const nodesGraphWidth = nodesGraph[0].length - 1;\r\n  const { row, col } = node;\r\n\r\n  if (row + 1 <= nodesGraphHeight) neighbors.push(nodesGraph[row + 1][col]);\r\n  if (row - 1 >= 0) neighbors.push(nodesGraph[row - 1][col]);\r\n  if (col + 1 <= nodesGraphWidth) neighbors.push(nodesGraph[row][col + 1]);\r\n  if (col - 1 >= 0) neighbors.push(nodesGraph[row][col - 1]);\r\n\r\n  return neighbors;\r\n}\r\n\r\nfunction reconstructPath(endNode) {\r\n  if (!endNode.cameFrom) return [];\r\n\r\n  const path = [];\r\n  let currentNode = endNode;\r\n  while (currentNode) {\r\n    path.push([currentNode.row, currentNode.col]);\r\n    currentNode = currentNode.cameFrom;\r\n  }\r\n  return path.reverse();\r\n}",
  },
  {
    algo: "Dijkstra-Algorithm",
    code: "/* - Dijkstra's Algorithm: Shortest Path in a Weighted Graph\r\n\r\n Dijkstra's algorithm is a popular graph search algorithm used to\r\n find the shortest path between two nodes in a weighted graph.\r\n It's named after its inventor, Edsger W.\r\n Dijkstra, and is widely used in various applications,\r\n including navigation systems, network routing, and more.\r\n\r\nAlgorithm Overview: \r\n-------------------\r\n\r\n1. Initialize the distance of the start node to 0,\r\n and all other node distances to Infinity.\r\n2. Create a priority queue to keep track of nodes to visit,\r\n starting with the start node.\r\n3. While there are nodes to visit in the priority queue:\r\n - Get the node with the minimum distance from the queue.\r\n - Mark the current node as visited.\r\n - If the current node's distance is Infinity,\r\n there are no more paths to explore.\r\n - If we've reached the finish node, we're done.\r\n\r\n4. Get the neighbors of the current node.\r\n5. For each neighbor:\r\n - Skip walls and already visited nodes.\r\n - Calculate the tentative minimum distance to the neighbor.\r\n - If the tentative distance is greater than the current distance, skip it.\r\n - Update the neighbor's distance and previous node.\r\n - Add the neighbor to the priority queue if it's not already in it.\r\n6. Return the path from the finish node to the start node.\r\n\r\nPros: \r\n-----\r\n  - Dijkstra's algorithm guarantees the shortest path in \r\nweighted graphs with non-negative edge weights.\r\n  - It's easy to implement and understand.\r\n    - Suitable for finding the shortest path between two specific nodes.\r\n\r\nCons: \r\n-----\r\n  - Inefficient for graphs with negative edge weights or cycles.\r\n    - May not find the shortest path in the presence of negative weights.\r\n\r\nTime Complexity: \r\n----------------\r\n  - With a priority queue (heap), Dijkstra's algorithm\r\n has a time complexity of O((V + E) * log(V)),\r\n      where V is the number of nodes (vertices)\r\n and E is the number of edges in the graph.\r\n  - Without a priority queue, it has a time complexity of O(V^2),\r\n making it impractical for large graphs.\r\n\r\nUsage: \r\n------\r\n  - Dijkstra's algorithm is used in various applications, \r\n including route planning in navigation systems, network routing,\r\n and even in computer graphics for pathfinding.\r\n\r\n===================================================================*/\r\nfunction dijkstra(startNode, finishNode, nodesGraph) {\r\n  startNode.distanceFromStart = 0;\r\n\r\n  const nodesToVisit = new MinHeap([startNode]);\r\n\r\n  while (!nodesToVisit.isEmpty()) {\r\n    const currentNodeWithMinDistance = nodesToVisit.remove();\r\n\r\n    currentNodeWithMinDistance.visited = true;\r\n\r\n    if (currentNodeWithMinDistance.distanceFromStart === Infinity) break;\r\n\r\n    if (currentNodeWithMinDistance === finishNode) break;\r\n\r\n    const neighbors = getNeighbors(currentNodeWithMinDistance, nodesGraph);\r\n\r\n    for (const neighbor of neighbors) {\r\n      if (neighbor.isWall || neighbor.visited) continue;\r\n\r\n      const neighborTentativeMinDistance =\r\n        currentNodeWithMinDistance.distanceFromStart + neighbor.weight;\r\n\r\n      if (neighborTentativeMinDistance >= neighbor.distanceFromStart) continue;\r\n\r\n      neighbor.distanceFromStart = neighborTentativeMinDistance;\r\n      neighbor.prevNode = currentNodeWithMinDistance;\r\n\r\n      if (!nodesToVisit.containsNode(neighbor)) nodesToVisit.insert(neighbor);\r\n      else nodesToVisit.update(neighbor);\r\n    }\r\n  }\r\n  return reconstructPath(finishNode);\r\n}\r\n\r\nfunction getNeighbors(node, nodesGraph) {\r\n  const neighbors = [];\r\n  const nodesGraphHeight = nodesGraph.length - 1;\r\n  const nodesGraphWidth = nodesGraph[0].length - 1;\r\n  const { row, col } = node;\r\n\r\n  if (row + 1 <= nodesGraphHeight) neighbors.push(nodesGraph[row + 1][col]);\r\n  if (row - 1 >= 0) neighbors.push(nodesGraph[row - 1][col]);\r\n  if (col + 1 <= nodesGraphWidth) neighbors push(nodesGraph[row][col + 1]);\r\n  if (col - 1 >= 0) neighbors.push(nodesGraph[row][col - 1]);\r\n\r\n  return neighbors;\r\n}\r\n\r\nfunction reconstructPath(endNode) {\r\n  if (!endNode.cameFrom) return [];\r\n\r\n  const path = [];\r\n  let currentNode = endNode;\r\n  while (currentNode) {\r\n    path.push([currentNode.row, currentNode.col]);\r\n    currentNode = currentNode.cameFrom;\r\n  }\r\n  return path.reverse();\r\n}",
  },
{
  algo: "Depth-First-Search",
    code: "/*========Depth-First Search Algorithm: Exploring Graphs Using a Stack==========\r\n\r\nDepth-First Search (DFS) is a fundamental graph traversal algorithm used \r\n to explore graphs or trees. It's known for its simplicity and ability to efficiently \r\n navigate large structures. In this tutorial, we'll delve into how DFS works,\r\n its pros and cons, time complexity, and common applications.\r\n\r\nAlgorithm Overview: \r\n-------------------\r\n\r\n1. Initialize a stack with the starting node and set its distance to 0.\r\n\r\n2. Start exploring from the initial node by pushing it onto the stack.\r\n\r\n3. Mark the initial node as visited and set its distance from the start to 0.\r\n\r\n4. While the stack isn't empty: \r\n  - Find the next unvisited neighbor of the current node.\r\n    - If a neighbor exists: \r\n      - Push the neighbor onto the stack.\r\n      - Mark the neighbor as visited and update its distance and previous node.\r\n      - If the neighbor is the finish node, exit the loop.\r\n      - Set the current node to the neighbor.\r\n    - If there's no unvisited neighbor, pop the current node from the stack.\r\n\r\n5. If a path to the finish node is found, return it.\r\n\r\nPros: \r\n-----\r\n  - DFS is easy to implement and efficient for exploring large structures.\r\n  - It can find paths and cycles in graphs and doesn't require storing the entire graph.\r\n\r\nCons: \r\n-----\r\n  - It may not find the shortest path in weighted graphs.\r\n  - DFS can get stuck in infinite loops without proper termination conditions.\r\n  - It's incomplete for certain graphs requiring specific search orders.\r\n\r\nTime Complexity: \r\n----------------\r\n  - DFS has a time complexity of O(V + E), making it efficient for many applications.\r\n\r\nUsage: \r\n------\r\n  - DFS is used in solving mazes, exploring connected components, and puzzle solving.*/ \r\n\r\n function depthFirstSearch(startNode, finishNode, nodesGraph) {\r\n  const stack = [startNode];\r\n  startNode.visitedDFS = true;\r\n  startNode.distanceFromStart = 0;\r\n  let currentNode = startNode;\r\n  while (stack.length) {\r\n    const nextNode = getNeighbor(currentNode, nodesGraph);\r\n    if (nextNode) {\r\n      stack.push(nextNode);\r\n      nextNode.visited = true;\r\n      nextNode.distanceFromStart = currentNode.distanceFromStart + 1;\r\n      nextNode.prevNode = currentNode;\r\n      if (nextNode === finishNode) break;\r\n      currentNode = nextNode;\r\n    } else {\r\n      currentNode = stack.pop();\r\n    }\r\n  }\r\n  return reconstructPath(finishNode);\r\n}\r\n\r\nfunction getNeighbor(node, nodesGraph) {\r\n  const { row, col } = node;\r\n  if (row < nodesGraph.length - 1) {\r\n    const { visited, isWall } = nodesGraph[row + 1][col];\r\n    if (!visited && !isWall) return nodesGraph[row + 1][col];\r\n  }\r\n  if (col < nodesGraph[0].length - 1) {\r\n    const { visited, isWall } = nodesGraph[row][col + 1];\r\n    if (!visited && !isWall) return nodesGraph[row][col + 1];\r\n  }\r\n  if (row > 0) {\r\n    const { visited, isWall } = nodesGraph[row - 1][col];\r\n    if (!visited && !isWall) return nodesGraph[row - 1][col];\r\n  }\r\n  if (col > 0) {\r\n    const { visited, isWall } = nodesGraph[row][col - 1];\r\n    if (!visited and !isWall) return nodesGraph[row][col - 1];\r\n  }\r\n  return false;\r\n}\r\n\r\nfunction reconstructPath(finishNode) {\r\n  if (!finishNode.prevNode) return [];\r\n  const pathNodes = [];\r\n  let currentNode = finishNode;\r\n  while (currentNode) {\r\n    pathNodes.push(currentNode);\r\n    currentNode = currentNode.prevNode;\r\n  }\r\n  return pathNodes.reverse();\r\n}",
  },
{
  algo: "Breadth-First-Search",
    code: "/*Breadth-First Search Algorithm: Traversing Graphs Layer by Layer\r\n\r\nBreadth-First Search (BFS) is a graph traversal algorithm known\r\n for its efficiency in exploring graphs layer by layer.\r\n In this comprehensive tutorial, we'll explain how BFS works,\r\n its strengths, limitations, time complexity, and common applications,\r\n all followed by a detailed code implementation with comments.\r\n\r\nAlgorithm Overview: \r\n-------------------\r\n\r\n1. Initialize a queue with the starting node and set its distance to 0.\r\n\r\n2. Start exploring from the initial node by dequeuing it from the queue.\r\n\r\n3. Mark the initial node as visited and set its distance from the start to 0.\r\n\r\n4. While the queue isn't empty: \r\n  - Get the neighbors of the current node.\r\n    - For each unvisited neighbor: \r\n      - Mark the neighbor as visited and set its distance and previous node.\r\n      - If the neighbor is the finish node, stop the exploration.\r\n      - Enqueue the neighbor to the queue.\r\n\r\n5. If a path to the finish node is found, return it.\r\n\r\nPros: \r\n-----\r\n  - BFS guarantees the shortest path in unweighted graphs.\r\n  - It's useful for finding the shortest path, connectivity analysis, and more.\r\n\r\nCons: \r\n-----\r\n  - Inefficient for graphs with high branching factors or weighted edges.\r\n  - May not work for extremely large graphs due to memory requirements.\r\n\r\nTime Complexity: \r\n----------------\r\n  - BFS has a time complexity of O(V + E), making it efficient for most applications.\r\n\r\nUsage: \r\n------\r\n  - BFS is applied in network analysis, web crawling, shortest path finding, and more.\r\n\r\n */ \r\n\r\n export default function breadthFirstSearch(startNode, finishNode, nodesGraph) {\r\n  let queue = [startNode];\r\n  startNode.visited = true;\r\n  startNode.distanceFromStart = 0;\r\n  while (queue.length) {\r\n    const currentNode = queue.shift();\r\n    const neighbors = getNeighbors(currentNode, nodesGraph);\r\n    for (const neighbor of neighbors) {\r\n      neighbor.visited = true;\r\n      neighbor.distanceFromStart = currentNode.distanceFromStart + 1;\r\n      neighbor.prevNode = currentNode;\r\n      if (neighbor === finishNode) break;\r\n      else queue.push(neighbor);\r\n    }\r\n  }\r\n  return reconstructPath(finishNode);\r\n}\r\n\r\nfunction getNeighbors(node, nodesGraph) {\r\n  const neighbors = [];\r\n  const { row, col } = node;\r\n  if (row < nodesGraph.length - 1) neighbors.push(nodesGraph[row + 1][col]);\r\n  if (col < nodesGraph[0].length - 1) neighbors.push(nodesGraph[row][col + 1]);\r\n  if (row > 0) neighbors push(nodesGraph[row - 1][col]);\r\n  if (col > 0) neighbors.push(nodesGraph[row][col - 1]);\r\n  return neighbors.filter(({ visited, isWall }) => !visited && !isWall);\r\n}\r\n\r\nfunction reconstructPath(finishNode) {\r\n  if (!finishNode.prevNode) return [];\r\n  const pathNodes = [];\r\n  let currentNode = finishNode;\r\n  while (currentNode) {\r\n    pathNodes.push(currentNode);\r\n    currentNode = currentNode.prevNode;\r\n  }\r\n  return pathNodes.reverse();\r\n}",
  },
{
  algo: "Selection-Sort",
    code: "/*Selection Sort Algorithm: Simple Sorting by Selection\r\n\r\nSelection Sort is a straightforward comparison-based sorting algorithm \r\nthat repeatedly selects the minimum element from an unsorted part of the array \r\nand places it at the beginning.\r\n In this detailed tutorial, we'll delve into how Selection Sort works,\r\n its strengths, weaknesses, time complexity, space complexity,\r\n frequently asked questions, and other essential insights.\r\n\r\nAlgorithm Overview: \r\n-------------------\r\n\r\n1. Start with an initial assumption that the first element \r\nis the minimum (min).\r\n\r\n2. Iterate through the array and find the actual minimum\r\n element by comparing it with the rest of the elements.\r\n If a smaller element is found, update min.\r\n\r\n3. Swap the found minimum element with the first element,\r\n moving it to its correct position at the \r\nbeginning of the array.\r\n\r\n4. Repeat the process, excluding the already sorted part, \r\nuntil the entire array is sorted.\r\n\r\nPros: \r\n-----\r\n  - Selection Sort is simple to understand and implement.\r\n  - It performs a minimal number of swaps, making it useful when write operations are expensive.\r\n  - Selection Sort works well for small datasets\r\n or when the memory write operation is costly.\r\n\r\nCons: \r\n-----\r\n  - The time complexity of Selection Sort is O(n^2) in all cases,\r\n making it inefficient for large datasets.\r\n  - It doesn't adapt to the input; \r\nit performs the same number of comparisons for \r\nalready sorted or reverse-sorted arrays.\r\n  - Selection Sort isn't stable; it may change the relative order of equal elements.\r\n\r\nTime Complexity: \r\n----------------\r\n  - Selection Sort has a time complexity of O(n^2),\r\n where n is the number of elements in the array.\r\n It performs n(n-1)/2 comparisons and n swaps in the worst case.\r\n\r\nSpace Complexity: \r\n-----------------\r\n  - Selection Sort has a space complexity of O(1)\r\n since it only uses a constant amount of additional \r\nspace for swapping variables.\r\n\r\nFAQs:\r\n---\r\n  Q: Is Selection Sort useful in any scenarios?\r\n  A: Selection Sort can be useful when memory writes are \r\nexpensive due to its minimal number of swaps.\r\n However, it's typically less efficient than other sorting algorithms\r\n for large datasets.\r\n\r\n  Q: Is Selection Sort stable?\r\n  A: No, Selection Sort is not stable.\r\n It may change the relative order of equal elements.\r\n\r\n  Q: What is the best-case time complexity of Selection Sort?\r\n  A: The best-case time complexity is O(n^2), the same as the worst case,\r\n as Selection Sort performs the same number of comparisons and swaps\r\n regardless of input.\r\n\r\nAlgorithm Code: \r\n----------------*/ \r\n\r\nfunction selectionSort(array) {\r\n  let min = 0;\r\n  for (let i = 0; i < array.length; i++) {\r\n    min = i;\r\n    for (let j = i; j < array.length; j++) {\r\n      if (array[j] < array[min]) min = j;\r\n    }\r\n    swap(array, min, i);\r\n  }\r\n  return array;\r\n}\r\n\r\nfunction swap(array, i, j) {\r\n  [array[i], array[j]] = [array[j], array[i]];\r\n}",
  },
{
  algo: "Bubble-Sort",
    code: "/*Bubble Sort Algorithm: Simple Sorting by Repeated Swaps\r\n\r\nBubble Sort is a straightforward comparison-based sorting algorithm\r\n that repeatedly steps through the list, compares adjacent elements,\r\n and swaps them if they are in the wrong order.\r\n In this detailed tutorial, we will explore how Bubble Sort works,\r\n its advantages, drawbacks, time complexity, space complexity,\r\n and common questions about the algorithm.\r\n\r\nAlgorithm Overview: \r\n-------------------\r\n\r\n1. Start with an unsorted array and a flag 'isSorted' set to false.\r\n\r\n2. Repeatedly traverse the array until no more swaps are made:\r\n  - Set 'isSorted' to true (assume the array is sorted).\r\n  - Compare adjacent elements and swap them if they are in the wrong order.\r\n  - If a swap is made, set 'isSorted' to false to continue the loop.\r\n  - Decrease the 'endIdx' (index) to ignore the last sorted \r\nelements in subsequent passes.\r\n\r\nPros: \r\n-----\r\n  - Bubble Sort is simple to understand and implement,\r\n making it a useful educational tool.\r\n  - It's suitable for small lists or nearly sorted lists.\r\n  - The algorithm doesn't require additional memory (in-place sorting).\r\n\r\nCons: \r\n-----\r\n  - Bubble Sort is relatively slow for large lists due\r\n to its quadratic time complexity.\r\n  - It's not suitable for real-world applications \r\nwith extensive data due to its inefficiency.\r\n  - There are more efficient sorting algorithms available for practical use.\r\n\r\nTime Complexity: \r\n----------------\r\n  - Bubble Sort has a time complexity of O(n^2)\r\n in the worst and average cases,\r\n where n is the number of elements in the array.\r\n  - In the best case (when the array is already sorted),\r\n it has a time complexity of O(n).\r\n\r\nSpace Complexity: \r\n-----------------\r\n  - Bubble Sort has a space complexity of O(1)\r\n because it sorts the elements in place without requiring\r\n additional memory.\r\n\r\nFAQ:\r\n\r\nQ: When should I use Bubble Sort?\r\nA: Bubble Sort is best suited for educational purposes or\r\n sorting very small lists where simplicity is a priority.\r\n\r\nQ: Is Bubble Sort stable?\r\nA: Yes, Bubble Sort is a stable sorting algorithm.\r\n\r\nQ: What is the main drawback of Bubble Sort?\r\nA: Its main drawback is its quadratic time complexity,\r\n which makes it inefficient for large datasets.\r\n\r\nAlgorithm Code: \r\n----------------*/\r\n\r\nfunction bubbleSort(array) {\r\n  let isSorted = false;\r\n  let endIdx = array.length - 1;\r\n  while (!isSorted) {\r\n    isSorted = true;\r\n    for (let i = 0; i < endIdx; i++) {\r\n      if (array[i] > array[i + 1]) {\r\n        swap(array, i, i + 1);\r\n        isSorted = false;\r\n      }\r\n    }\r\n    endIdx--;\r\n  }\r\n  return array;\r\n}\r\n\r\nfunction swap(array, i, j) {\r\n  [array[i], array[j]] = [array[j], array[i]];\r\n}",
  },
{
  algo: "Insertion-Sort",
    code: "/*Insertion Sort Algorithm: Simple & Efficient Sorting\r\n\r\nInsertion Sort is a straightforward yet efficient\r\n comparison-based sorting algorithm.\r\n In this comprehensive tutorial, we'll explore how Insertion Sort works,\r\n its advantages, drawbacks, time complexity, space complexity,\r\n FAQs, and much more.\r\n\r\nAlgorithm Overview: \r\n-------------------\r\n\r\n1. Starting from the second element, \r\ncompare it to the previous elements, \r\nand insert it into the correct position\r\n within the sorted section of the array.\r\n\r\n2. Repeatedly perform this process until the entire array is sorted.\r\n\r\nPros: \r\n-----\r\n  - Insertion Sort is simple to implement and intuitive.\r\n  - It's efficient for small arrays or nearly sorted data.\r\n  - Adaptive and stable, making it suitable for real-time applications \r\n and sorting small datasets.\r\n\r\nCons: \r\n-----\r\n  - Inefficient for large datasets or mostly unsorted \r\ndata due to its quadratic time complexity.\r\n  - Not recommended for sorting linked lists due \r\nto its frequent element shifting.\r\n\r\nTime Complexity: \r\n----------------\r\n  - Best-case: O(n) when the data is nearly sorted, \r\nmaking it one of the fastest sorting algorithms in this scenario.\r\n  - Worst-case: O(n^2) when the data is reverse-sorted, \r\nwhich can be slow for large datasets.\r\n\r\nSpace Complexity: \r\n-----------------\r\n  - O(1) - Insertion Sort is an in-place sorting algorithm,\r\n which means it doesn't require additional memory \r\nexcept for a few variables.\r\n\r\nFAQs: \r\n-----\r\n  1. When should I use Insertion Sort?\r\n     - Use it for small datasets or when you know the data is already nearly sorted.\r\n  2. Is Insertion Sort stable?\r\n     - Yes, it's a stable sorting algorithm.\r\n  3. Can Insertion Sort be used for sorting linked lists?\r\n     - It's not recommended for linked lists due to \r\nits high time complexity for element shifting.\r\n\r\nAlgorithm Code: \r\n----------------*/\r\n\r\nfunction insertionSort(array) {\r\n  for (let i = 1; i < array.length; i++) {\r\n    for (let j = i; j > 0; j--) {\r\n      if (array[j] < array[j - 1]) {\r\n        swap(array, j, j - 1);\r\n      }\r\n    }\r\n  }\r\n  return array;\r\n}\r\n\r\nfunction swap(array, i, j) {\r\n  [array[i], array[j]] = [array[j], array[i]];\r\n}",
  },
{
  algo: "Radix-Sort",
    code: "/*Radix Sort Algorithm: Sorting by Digits\r\n\r\nRadix Sort is\r\n a non-comparative integer sorting algorithm that operates\r\n by distributing elements into buckets according to their individual digits.\r\n In this comprehensive tutorial, we'll explore how Radix Sort works,\r\n its advantages, drawbacks, time complexity,\r\n and potential use cases.\r\n\r\nAlgorithm Overview: \r\n-------------------\r\n\r\n1. If the array has 1 or no elements, return it (it's already sorted).\r\n\r\n2. Find the maximum number in the array to determine the\r\n number of digits in it.\r\n\r\n3. Iterate through each digit's place value from the least significant\r\n digit to the most significant digit.\r\n  - Use Counting Sort for each digit's place value to sort the array.\r\n  - Repeat this process for all digits until the entire \r\narray is sorted by digits.\r\n\r\nPros: \r\n-----\r\n  - Radix Sort is highly efficient for integers,\r\n as it doesn't require comparisons between elements.\r\n  - It's faster for a large number of elements with small\r\n digit counts compared to other sorting algorithms.\r\n  - Radix Sort is stable and can be used for stable sorting\r\n when a stable sub-sorting algorithm is applied.\r\n\r\nCons: \r\n-----\r\n  - Radix Sort is not suitable for sorting floating-point numbers,\r\n as it doesn't handle the decimal parts.\r\n  - It's less effective for arrays with a large range of numbers,\r\n as it can create a significant number of buckets.\r\n  - The algorithm requires extra space for temporary arrays,\r\n making it less memory-efficient.\r\n\r\nTime Complexity: \r\n----------------\r\n  - Radix Sort has a time complexity of O(k * (n + b)),\r\n where k is the number of digits in the maximum number,\r\n n is the number of elements, and b is the base for representing numbers\r\n (typically 10 for base-10 numbers).\r\n  - When the maximum number of digits is relatively small,\r\n Radix Sort can outperform comparison-based sorting algorithms\r\n with O(n log n) complexity.\r\n\r\nUsage: \r\n------\r\n  - Radix Sort is particularly useful for sorting large integers,\r\n such as 32-bit or 64-bit integers.\r\n  - It's employed in applications where integer sorting is a critical requirement,\r\n including data analysis, string sorting, and lexical analysis.\r\n\r\nAlgorithm Code: \r\n----------------*/\r\n\r\nfunction radixSort(array) {\r\n  if (array.length <= 1) return array;\r\n  const maxNumber = Math.max(...array);\r\n  let digit = 0;\r\n  while (maxNumber / 10 ** digit > 0) {\r\n    countingSort(array, digit);\r\n    digit++;\r\n  }\r\n  return array;\r\n}\r\n\r\nfunction countingSort(array, digit) {\r\n  const sortedArray = new Array(array.length).fill(0);\r\n  const countArray = new Array(10).fill(0);\r\n  const digitColumn = 10 ** digit;\r\n  for (const num of array) {\r\n    const numAtDigitColumn = Math.floor(num / digitColumn) % 10;\r\n    countArray[numAtDigitColumn]++;\r\n  }\r\n  for (let i = 1; i < 10; i++) {\r\n    countArray[i] += countArray[i - 1];\r\n  }\r\n  for (let i = array.length - 1; i >= 0; i--) {\r\n    let numAtDigitColumn = Math.floor(array[i] / digitColumn) % 10;\r\n    const sortedIdx = --countArray[numAtDigitColumn];\r\n    sortedArray[sortedIdx] = array[i];\r\n  }\r\n  for (let i = 0; i < array.length; i++) {\r\n    array[i] = sortedArray[i];\r\n  }\r\n}"

  },
{
  algo: "Merge-Sort",
    code: "/*Merge Sort Algorithm: Efficient Divide and Conquer Sorting\r\n\r\nMerge Sort is a widely-used comparison-based sorting algorithm known for its efficiency\r\n and stability. In this comprehensive tutorial, we'll delve into the workings of Merge Sort,\r\n its advantages and disadvantages, time complexity, and practical applications.\r\n You'll also find detailed code with inline comments for a better understanding.\r\n\r\nAlgorithm Overview: \r\n-------------------\r\n\r\n1. If the array has one or zero elements, it's already sorted, so return it.\r\n\r\n2. Find the middle of the array and split it into two subarrays.\r\n\r\n3. Recursively apply Merge Sort to both subarrays.\r\n\r\n4. Merge the sorted subarrays back into a single, sorted array.\r\n\r\n5. Return the merged array.\r\n\r\nPros: \r\n-----\r\n  - Merge Sort is stable, meaning it maintains the relative order of equal elements.\r\n  - It's a highly predictable algorithm with a consistent time complexity.\r\n  - Efficient for sorting linked lists as well as arrays.\r\n\r\nCons: \r\n-----\r\n  - Merge Sort has a space complexity of O(n), which may not be suitable for large data sets.\r\n\r\nTime Complexity: \r\n----------------\r\n  - Merge Sort has a time complexity of O(n log n), making it ideal for large datasets.\r\n  - It outperforms other sorting algorithms, such as Quick Sort, for nearly sorted data.\r\n\r\nUsage: \r\n------\r\n  - Merge Sort is frequently used for external sorting and in language libraries.\r\n  - It's suitable for stable sorting and preserving the relative order of equal elements.\r\n\r\n*/\r\n\r\nfunction mergeSort(array) {\r\n  if (array.length <= 1) return array;\r\n  let mid = Math.floor(array.length / 2);\r\n  let left = mergeSort(array.slice(0, mid));\r\n  let right = mergeSort(array.slice(mid));\r\n  return merge(left, right);\r\n}\r\n\r\nfunction merge(array1, array2) {\r\n  let i = 0;\r\n  let j = 0;\r\n  let sorted = [];\r\n  while (i < array1.length && j < array2.length) {\r\n    if (array2[j].height > array1[i].height) {\r\n      sorted.push(array1[i++]);\r\n    } else {\r\n      sorted.push(array2[j++]);\r\n    }\r\n  }\r\n  while (i < array1.length) {\r\n    sorted.push(array1[i++]);\r\n  }\r\n  while (j < array2.length) {\r\n    sorted.push(array2[j++]);\r\n  }\r\n  return sorted;\r\n}",
  },
{
  algo: "Quick-Sort",
    code: "/*Quick Sort Algorithm: Efficient Divide and Conquer Sorting\r\n\r\n  Quick Sort is a widely used,\r\n   efficient sorting algorithm that divides an array\r\n   into smaller sub-arrays, recursively sorts them,\r\n   and combines the sorted sub-arrays. In this\r\n   comprehensive tutorial, we'll explore the workings,\r\n   advantages, disadvantages, time complexity,\r\n   and detailed implementation of Quick Sort,\r\n   providing a step-by-step guide to understanding this\r\n   popular sorting algorithm.\r\n\r\nAlgorithm Overview: \r\n-------------------\r\n\r\n1. Select a 'pivot' element from the array.\r\n\r\n2. Reorder the array so that elements less than\r\n   the pivot are on the left, and elements greater\r\n   than the pivot are on the right. \r\n  The pivot is now in its final sorted position.\r\n\r\n3. Recursively sort the sub-arrays on the left and right of the pivot.\r\n\r\n4. Combine the sub-arrays to form the final sorted array.\r\n\r\nPros: \r\n-----\r\n  - Quick Sort is one of the fastest sorting algorithms\r\n   in practice and widely used in various applications.\r\n  - It's an in-place sorting algorithm,\r\n   minimizing the need for additional memory.\r\n  - Efficient for both small and large data sets.\r\n\r\nCons: \r\n-----\r\n  - Not stable, meaning it may change the\r\n   relative order of equal elements.\r\n  - Performance can degrade with an already sorted\r\n   array or when a poorly chosen pivot is used.\r\n\r\nTime Complexity: \r\n----------------\r\n  - Quick Sort averages O(n * log(n)) comparisons and swaps \r\n  for a random order of input data.\r\n  - It's efficient and practical for real-world\r\n   data sets of varying sizes.\r\n\r\nTutorial:\r\n----------\r\nQuick Sort divides the array into sub-arrays, recursively sorts them,\r\n   and combines them back to produce the final sorted array.\r\n\r\nHere's a step-by-step breakdown of the algorithm:\r\n\r\n1. Choose a 'pivot' element from the array.\r\n   Common choices are the first or last element, or a random element.\r\n\r\n2. Reorder the array so that elements less than the pivot\r\n   are placed on the left, and elements greater than the pivot\r\n   are placed on the right. The pivot itself is in its final sorted position.\r\n   This is done using two pointers,\r\n   one that moves from the left and another from the right,\r\n   swapping elements when necessary.\r\n\r\n3. Recursively apply Quick Sort to the sub-arrays\r\n   on the left and right of the pivot, sorting them in the same manner.\r\n   Repeat this process until all sub-arrays are sorted.\r\n\r\n4. Finally, combine the sub-arrays to form the fully sorted array.\r\n   The result is an array with all elements sorted in ascending order.\r\n\r\nQuick Sort is a widely used sorting algorithm due to its efficiency\r\n   and practicality for both small and large data sets.\r\n\r\n============================================================================\r\n    */\r\n   function quickSort(array, left, right) {\r\n  let index;\r\n  if (array.length > 1) {\r\n    index = partition(array, left, right);\r\n    if (left < index - 1) {\r\n      quickSort(array, left, index - 1);\r\n    }\r\n    if (index < right) {\r\n      quickSort(array, index, right);\r\n    }\r\n  }\r\n  return array;\r\n}\r\n\r\nfunction partition(array, left, right) {\r\n  let mid = Math.floor((right + left) / 2);\r\n  let i = left;\r\n  let j = right;\r\n  let pivot = array[mid];\r\n  while (i <= j) {\r\n    while (array[i] < pivot) i++;\r\n    while (array[j] > pivot) j--;\r\n    if (i <= j) swap(array, i++, j--);\r\n  }\r\n  return i;\r\n}\r\n\r\nfunction swap(array, i, j) {\r\n  [array[i], array[j]] = [array[j], array[i]];\r\n}",
  },
{
  algo: "Heap-Sort",
    code: "/*Heap Sort Algorithm: Efficient In-Place Sorting\r\n\r\n Heap Sort is a highly efficient comparison-based sorting algorithm\r\n that can be used to sort an array in-place.\r\n It's known for its simplicity, stability, and\r\n constant-time worst-case performance.\r\n In this comprehensive tutorial, we'll delve into how Heap Sort works,\r\n its pros and cons, time complexity, and common applications.\r\n\r\nAlgorithm Overview: \r\n-------------------\r\n\r\nHeap Sort involves the following steps: \r\n\r\n1. Build a max heap from the input array,\r\n which creates a binary tree-like structure where\r\n the parent nodes are greater than their children. \r\nThis step ensures the maximum element is at the root.\r\n\r\n2. Repeatedly swap the root element (maximum) with\r\n the last element of the heap, reduce the size of the heap,\r\n and maintain the max heap properties by performing a sift-down operation.\r\n This step places the maximum element at the end of the array.\r\n\r\n3. Repeat step 2 for the remaining unsorted portion of the array\r\n until the entire array is sorted.\r\n\r\nPros: \r\n-----\r\n  - Heap Sort is an efficient, stable sorting algorithm \r\nwith a consistent O(n log n) time complexity.\r\n  - It is an in-place sorting algorithm that requires\r\n a constant amount of extra memory.\r\n  - Suitable for large datasets where worst-case performance is important.\r\n\r\nCons: \r\n-----\r\n  - Heap Sort is slower than some other sorting \r\nalgorithms for small datasets.\r\n  - It does not perform well on lists that are almost sorted.\r\n\r\nTime Complexity: \r\n----------------\r\n  - Heap Sort has an average and worst-case time complexity \r\nof O(n log n), making it efficient for most use cases.\r\n\r\nUsage: \r\n------\r\n  - Heap Sort is used in various applications, \r\nincluding implementing priority queues and external sorting methods.\r\n\r\n\r\n*/function heapSort(array) {\r\n  buildMaxHeap(array);\r\n  for (let endIdx = array.length - 1; endIdx >= 1; endIdx--) {\r\n    swap(0, endIdx, array);\r\n    siftDown(0, endIdx - 1, array);\r\n  }\r\n  return array;\r\n}\r\n\r\nfunction buildMaxHeap(array) {\r\n  const firstParentIdx = Math.floor((array.length - 2) / 2);\r\n  for (let i = firstParentIdx; i >= 0; i--) {\r\n    siftDown(i, array.length - 1, array);\r\n  }\r\n}\r\n\r\nfunction siftDown(parentIdx, endIdx, heap) {\r\n  let childOneIdx = parentIdx * 2 + 1;\r\n  while (childOneIdx <= endIdx) {\r\n    const childTwoIdx = childOneIdx + 1 <= endIdx && childOneIdx + 1;\r\n    const greaterChildIdx =\r\n      childTwoIdx && heap[childTwoIdx] > heap[childOneIdx]\r\n        ? childTwoIdx\r\n        : childOneIdx;\r\n    if (heap[greaterChildIdx] > heap[parentIdx]) {\r\n      swap(greaterChildIdx, parentIdx, heap);\r\n      parentIdx = greaterChildIdx;\r\n      childOneIdx = parentIdx * 2 + 1;\r\n    } else return;\r\n  }\r\n}\r\n\r\nfunction swap(i, j, array) {\r\n  [array[i], array[j]] = [array[j], array[i]];\r\n}"

  },
];

export default snippets;
